#encoding=utf8

#############################################################################
# Copyright (c) 2014  - Beijing Intelligent Star, Inc.  All rights reserved

#�ļ�����spider.conf
#���ܣ�������߳����������ļ�
#������ʷ��
#2014-02-07����ΰ�գ�����������


[spider]
#����id
spider_id = -1
#�����ļ�����·��
get_spider_config_from =  d:\workspace\pyWorks\spider\syq_url_ruls1.py
#����ͳ�ƽ�����ص�ַ
#send_crawl_result_to = http://192.168.110.24/task.php
send_crawl_result_to = 
get_spider_param_from = http://192.168.110.24/task.php/Data/index
#��ʼ���б��̺߳�����ҳ�߳�ʱ�ļ��
list_detail_interval = 1
#�����˳��źź󣬼���ִ�����ʱ��
exit_timeout = 90
#���ݱ���
data_encoding = utf8
#ÿ���������������ļ��󣬸������ļ��������д���;
repeat_times = 1000
#�Ƿ����ץȡ����
show_data = True
#
adsl_id = -1

[dedup]
#ȥ�ؿ��ַ
#dedup_uri = 192.168.110.110:6379/0
dedup_uri = 127.0.0.1:6379/0
dedup_key = dedup

[threading]
#������Ŀ
process_num = 1
#�б�ҳ�߳���
list_page_thread_num = 2
#��ϸҳ�߳���
detail_page_thread_num = 100
#���ݷ����߳���
data_queue_thread_num = 1
#�������з�ʽ: threading, gevent
crawler_mode = gevent

[http]
user_agent = r'''Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.101 Safari/537.36'''

#�Ƿ�ʹ�ô���
proxy_enable = False
#ͬһ�����ʼ��������Ŀ
available_proxy_num = 30
#ÿ��������������ظ�ʹ�ô���
proxy_max_num = 5
#�����ļ�·��
proxy_url = http://192.168.84.4/proxy.txt
#�Ƿ�֧��ҳ��ѹ��(gzip deflate)
compression = True
http_timeout = 15
cookie_enable = False

[daemon_app]
stdin_path = /dev/null
stdout_path = /dev/tty
stderr_path = /dev/tty
pidfile_path = /tmp/spiderdaemon.pid
pidfile_timeout = 5

[data_db]
#������־��Ϣ��ŵ�ַ
#spider_log_db = redis://192.168.110.110:6379/8
spider_log_db = 127.0.0.1:6379/0
#����ץȡҳ�����ݴ�ŵ�ַ
#spider_data_db = redis://192.168.110.140/3/data
spider_data_db = redis://127.0.0.1/0/data

#�б�ҳЭ�����ݴ�ŵ�ַ
#crawler_list_data = redis://192.168.100.15/3
crawler_list_data = redis://127.0.0.1/0
